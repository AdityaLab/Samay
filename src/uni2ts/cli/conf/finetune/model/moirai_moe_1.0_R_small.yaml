# load a pytorch lightning checkpoint
_target_: uni2ts.model.moirai.MoiraiFinetune.load_from_checkpoint
module_kwargs:
  _target_: builtins.dict
  attn_dropout_p: 0
  d_ff: 512
  d_model: 384
  distr_output:
    _target_: uni2ts.distribution.mixture.MixtureOutput
    components:
      - _target_: uni2ts.distribution.student_t.StudentTOutput
      - _target_: uni2ts.distribution.normal.NormalFixedScaleOutput
        scale: 0.001
      - _target_: uni2ts.distribution.negative_binomial.NegativeBinomialOutput
      - _target_: uni2ts.distribution.log_normal.LogNormalOutput
  dropout_p: 0
  max_seq_len: 512
  num_layers: 6
  patch_sizes: ${as_tuple:[8, 16, 32, 64, 128]}
  scaling: true
min_patches: 2
min_mask_ratio: 0.15
max_mask_ratio: 0.5
max_dim: 128
loss_func:
  _target_: uni2ts.loss.packed.PackedNLLLoss
val_metric:
  - _target_: uni2ts.loss.packed.PackedMSELoss
  - _target_: uni2ts.loss.packed.PackedNRMSELoss
    normalize: absolute_target_squared
lr: 1e-3
weight_decay: 1e-1
beta1: 0.9
beta2: 0.98
num_training_steps: ${mul:${trainer.max_epochs},${train_dataloader.num_batches_per_epoch}}
num_warmup_steps: 0
checkpoint_path: ...
