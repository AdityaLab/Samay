{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOIRAI Usage Example\n",
    "\n",
    "### Key features of the model:\n",
    "- **Multi-patch Layers:** Adapts to different granularities (frequencies) - different patch size for each granularity\n",
    "- **Probabilistic:** Predicts params of mix of distributions along with a confidence score for each distribution\n",
    "\n",
    "### Loading MOIRAI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External imports\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(\"src\"))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Local imports\n",
    "from samay.dataset import MoiraiDataset\n",
    "from samay.model import MoiraiTSModel\n",
    "\n",
    "# Load the pretrained model\n",
    "repo = \"Salesforce/moirai-moe-1.0-R-small\"\n",
    "config = {\n",
    "        \"context_len\": 128,\n",
    "        \"horizon_len\": 64,\n",
    "        \"num_layers\": 100,\n",
    "        \"model_type\": \"moirai-moe\",\n",
    "        \"model_size\": \"small\"\n",
    "    }\n",
    "\n",
    "moirai_model = MoiraiTSModel(repor=repo, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config for the electric transformer temperature dataset\n",
    "data_config = {\"name\" : \"ett\",\n",
    "                \"path\" : \"../src/samay/models/moment/data/ETTh1.csv\",\n",
    "                \"date_col\" : \"date\",\n",
    "                \"freq\": \"h\"\n",
    "            }\n",
    "\n",
    "df = pd.read_csv(data_config[\"path\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have 6 input features (all form `input_ts`) and the target column is the *Oil Temperature* (`OT`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset - for zero-shot forecasting\n",
    "test_dataset = MoiraiDataset(\n",
    "    name=data_config['name'],\n",
    "    mode=\"test\",\n",
    "    path=data_config['path'],\n",
    "    datetime_col=data_config['date_col'],\n",
    "    freq=data_config['freq'],\n",
    "    context_len=config['context_len'],\n",
    "    horizon_len=config['horizon_len'],\n",
    "    normalize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x for x in dir(test_dataset) if \"__\" not in x],end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data` is of `pd.DataFrame` type and `dataset` is of `torch.utils.data.Dataset` type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all = [x for x in iter(test_dataset.dataset)]\n",
    "len(test_all), test_all[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two parts to each instance (window) in `test_all` - the `input` (history) and the `label` which consists of the true value of the forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_all[0][0][\"target\"]), len(test_all[0][1][\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate zero-shot forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"date\"]>=\"2018-04-17 08:00:00\"][\"OT\"].values[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results, trues, preds, histories = moirai_model.evaluate(test_dataset, metrics=[\"MSE\", \"MASE\"])\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise forecast for a given window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "window_index = random.randint(0, len(histories) - 1)\n",
    "variate_no = random.randint(0, histories[window_index].shape[0] - 1)\n",
    "print(f\"Window index: {window_index}, Variate no: {variate_no}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = histories[window_index][variate_no, -config[\"context_len\"]:]\n",
    "true = trues[window_index][variate_no, :]\n",
    "pred = preds[window_index][variate_no, :]\n",
    "\n",
    "len(history), len(true), len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "num_forecasts = len(true)\n",
    "offset = len(history)\n",
    "\n",
    "# Plotting the first time series from history\n",
    "plt.plot(range(offset), history, label=f\"History ({offset} timesteps)\", c=\"darkblue\")\n",
    "\n",
    "# Plotting ground truth and prediction\n",
    "plt.plot(\n",
    "    range(offset, offset + num_forecasts),\n",
    "    true,\n",
    "    label=f\"Ground Truth ({num_forecasts} timesteps)\",\n",
    "    color=\"darkblue\",\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.plot(\n",
    "    range(offset, offset + num_forecasts),\n",
    "    pred,\n",
    "    label=f\"Forecast ({num_forecasts} timesteps)\",\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "\n",
    "plt.title(f\"ETTh1 (Hourly) -- (Window index: {window_index}, Variate no: {variate_no}\", fontsize=18)\n",
    "plt.xlabel(\"Time\", fontsize=14)\n",
    "plt.ylabel(\"Value\", fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune MOIRAI on ETT Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "path = \"../src/samay/models/uni2ts/cli/conf/finetune/model/moirai_small.yaml\"\n",
    "with open(path, \"r\") as file:\n",
    "    fin_config = yaml.safe_load(file)\n",
    "\n",
    "fin_config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config_path = \"../src/samay/models/uni2ts/cli/conf/finetune/default.yaml\"\n",
    "with open(data_config_path, \"r\") as file:\n",
    "    torch_config = yaml.safe_load(file)\n",
    "torch_config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of input features to Input projection layer is the patch size used by the model\n",
    "patch_size = moirai_model.model.module.in_proj.in_features_ls[0]\n",
    "patch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "train_dataset = MoiraiDataset(\n",
    "    name=data_config['name'],\n",
    "    mode=\"train\",\n",
    "    path=data_config['path'],\n",
    "    datetime_col=data_config['date_col'],\n",
    "    freq=data_config['freq'],\n",
    "    context_len=config['context_len'],\n",
    "    horizon_len=config['horizon_len'],\n",
    "    patch_size=patch_size,\n",
    "    normalize=False,\n",
    "    kwargs=torch_config[\"train_dataloader\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_kwargs = {\"batch_size\": torch_config[\"train_dataloader\"][\"batch_size\"], \"max_epochs\": torch_config[\"trainer\"][\"max_epochs\"], \"seed\": torch_config[\"seed\"],\n",
    "             \"tf32\": torch_config[\"tf32\"], \"mod_torch\": {k:v for k,v in torch_config[\"trainer\"].items() if k != \"_target_\" and type(v) not in [dict, list]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned = moirai_model.finetune(train_dataset, **ft_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "for x in iter(train_dataset.batched_data):\n",
    "    for k, v in x.items():\n",
    "        if isinstance(v, str) == False:\n",
    "            print(k, v.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load = train_dataset.get_dataloader()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
